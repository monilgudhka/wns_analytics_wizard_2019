{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WNS Analytics Wizard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(actual, predicted, predicted_probability):\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(actual, predicted)))\n",
    "    print(\"\")\n",
    "    print(\"For Class 1\")\n",
    "    print(\"f1 Score :\", f1_score(actual, predicted))\n",
    "    print(\"Precision Score :\",precision_score(actual, predicted))\n",
    "    print(\"Recall Score :\",recall_score(actual, predicted))\n",
    "    print(\"\")\n",
    "    print(\"For Class 0\")\n",
    "    print(\"f1 Score :\", f1_score(1-np.array(actual), 1-np.array(predicted)))\n",
    "    print(\"Precision Score :\",precision_score(1-np.array(actual), 1-np.array(predicted)))\n",
    "    print(\"Recall Score :\",recall_score(1-np.array(actual), 1-np.array(predicted)))\n",
    "    print(\"\")\n",
    "    print(\"AUROC :\",  roc_auc_score(actual, predicted_probability[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(impression_ids, is_clicks, method_name):\n",
    "    submission_frame = pd.DataFrame(is_clicks, index=impression_ids)\n",
    "    submission_frame.columns = ['is_click']\n",
    "    submission_frame.index.name = 'impression_id'\n",
    "    submission_frame.to_csv('data/report/'+method_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow(X, y, training_func, X_future, y_future_ids):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n",
    "    \n",
    "    model = training_func(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)\n",
    "    evaluate(y_test, y_pred, y_pred_prob)\n",
    "    \n",
    "    y_future_pred = model.predict_proba(X_future)[:,1]\n",
    "    generate_submission(y_future_ids, y_future_pred, training_func.__name__)\n",
    "    \n",
    "    return X_test, y_test, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"user_id\", \"app_code\", \"os_version\", \"is_4G\", \"freq_cat3\", \"unique_cat3\", \"unique_device\", \n",
    "                \"unique_items\", \"total_sessions\", \"last_active_session\", \"std_price\", \n",
    "                \"app_last_ad_seen\", \"last_ad_seen\", \"user_click_ratio\", \"app_click_ratio\"]\n",
    "category_cols = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.78620e+04, 4.22000e+02, 2.00000e+00, 0.00000e+00, 1.10000e+01,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 2.26734e+06,\n",
       "        0.00000e+00, 3.88800e+06, 3.88800e+06, 0.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Training Data\n",
    "training_df = pd.read_csv('data/train/train_feature.csv', index_col='impression_id', \n",
    "                          parse_dates=['impression_time'])\n",
    "training_df = training_df.fillna(0)\n",
    "\n",
    "# Removing records where user has no history\n",
    "training_df = training_df[(training_df.user_ads > 0) \n",
    "                              | (training_df.app_ads > 0)\n",
    "                             | (training_df.unique_items > 0)]\n",
    "\n",
    "training_df['hour'] = training_df.impression_time.dt.hour\n",
    "training_df['weekday'] = training_df.impression_time.dt.weekday\n",
    "\n",
    "X = training_df[feature_cols].values\n",
    "y = training_df['is_click'].values\n",
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90675, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = pd.read_csv('data/test/test_feature.csv', index_col='impression_id'\n",
    "                         , parse_dates=['impression_time'])\n",
    "testing_df = testing_df.fillna(0)\n",
    "testing_df['hour'] = testing_df.impression_time.dt.hour\n",
    "testing_df['weekday'] = testing_df.impression_time.dt.weekday\n",
    "\n",
    "X_future = testing_df[feature_cols].values\n",
    "y_future_ids = testing_df.index.values\n",
    "X_future.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "       0   1\n",
      "0  54728  18\n",
      "1   2622  27\n",
      "\n",
      "For Class 1\n",
      "f1 Score : 0.0200445434298441\n",
      "Precision Score : 0.6\n",
      "Recall Score : 0.010192525481313703\n",
      "\n",
      "For Class 0\n",
      "f1 Score : 0.976448758207251\n",
      "Precision Score : 0.9542807323452485\n",
      "Recall Score : 0.9996712088554415\n",
      "\n",
      "AUROC : 0.72194924438924\n"
     ]
    }
   ],
   "source": [
    "def ensemble_light_gbm(X_train, y_train):\n",
    "    lgb = LGBMClassifier(random_state=1024, num_leaves=22, max_depth=6, min_data_in_leaf=37, \n",
    "                         learning_rate=0.1, colsample_bytree=0.8, categorical_feature=category_cols)\n",
    "    lgb_grid = BaggingClassifier(lgb, n_estimators=10, n_jobs=10, random_state=41)\n",
    "    lgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    return lgb_grid\n",
    "\n",
    "X_test, y_test, y_pred = flow(X, y, ensemble_light_gbm, X_future, y_future_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
